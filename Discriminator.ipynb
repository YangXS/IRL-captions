{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from discriminator.discriminator_wrapper import DiscriminatorWrapper\n",
    "from coco_utils import load_coco_data_struct\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded vocab data.\n",
      "Embedding <class 'numpy.ndarray'> (1004, 304) float64\n",
      "Word to index <class 'dict'> 1004\n",
      "Index to word <class 'list'> 1004\n",
      "\n",
      "Loaded train data.\n",
      "Captions <class 'numpy.ndarray'> (400135, 17) int32\n",
      "Image indices <class 'numpy.ndarray'> (400135,) int32\n",
      "Image features <class 'numpy.ndarray'> (82783, 4096) float32\n",
      "Image urls <class 'numpy.ndarray'> (82783,) <U63\n",
      "\n",
      "Loaded val data.\n",
      "Captions <class 'numpy.ndarray'> (195954, 17) int32\n",
      "Image indices <class 'numpy.ndarray'> (195954,) int32\n",
      "Image features <class 'numpy.ndarray'> (40504, 4096) float32\n",
      "Image urls <class 'numpy.ndarray'> (40504,) <U63\n"
     ]
    }
   ],
   "source": [
    "attention_mode = False\n",
    "if attention_mode:\n",
    "    vocab_data, train_data, val_data = load_coco_data_struct(base_dir=\"datasets/self_process\", \n",
    "                                                         source_image_features='block5_conv4',\n",
    "                                                         is_caption_separated=True)\n",
    "else:\n",
    "    vocab_data, train_data, val_data = load_coco_data_struct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 0.0009905993938446045\n"
     ]
    }
   ],
   "source": [
    "iter_num = 1 # 350 iters should reach convergence\n",
    "batch_size = 1\n",
    "sess = tf.InteractiveSession()\n",
    "disc = DiscriminatorWrapper(train_data, val_data, vocab_data)\n",
    "tf.global_variables_initializer().run()\n",
    "train_loss, val_loss = disc.pre_train(sess, iter_num=iter_num, batch_size=batch_size)\n",
    "assert len(train_loss) == len(val_loss)\n",
    "assert len(train_loss) == iter_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"discriminator\"\n",
    "disc.save_model(sess, model_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_image_idx = np.array([1, 2, 3])\n",
    "captions = np.array([\"haha hehe\", \"hello wordl\", \"cat dogs one helloo\"])\n",
    "_, rewards, _ = disc.assign_reward(sess, \n",
    "                                   train_image_idx, \n",
    "                                   captions,\n",
    "                                   image_idx_from_training=True, \n",
    "                                   to_examine=False)\n",
    "assert rewards.shape[0] == len(train_image_idx)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/discr/discriminator\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "loaded_disc = DiscriminatorWrapper(train_data, val_data, vocab_data,\n",
    "                                   load_session=sess,\n",
    "                                   saved_model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, rewards_after_loaded, _ = loaded_disc.assign_reward(sess, \n",
    "                                                       train_image_idx, \n",
    "                                                       captions,\n",
    "                                                       image_idx_from_training=True, \n",
    "                                                       to_examine=False)\n",
    "\n",
    "assert np.array_equal(rewards, rewards_after_loaded), \"Loaded model should assign same rewards as trained model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: -0.0012067159404978156\n"
     ]
    }
   ],
   "source": [
    "online_all_loss, online_val_loss = loaded_disc.online_train(sess, iter_num=20, img_idxs=train_image_idx, caption_sentences=captions)\n",
    "\n",
    "assert len(online_all_loss) == len(online_val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

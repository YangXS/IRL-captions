{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discriminator.discriminator_wrapper import DiscriminatorWrapper\n",
    "from coco_utils import load_coco_data_struct\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from lstm import MaxLikelihoodLSTM, PolicyGradientLSTM\n",
    "from data import PGData, COCOData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_sess():\n",
    "    global sess\n",
    "    ruv = set(sess.run(tf.report_uninitialized_variables()))\n",
    "    uv = [v for v in tf.global_variables() if v.name.split(':')[0].encode('ascii') in ruv]\n",
    "    tf.variables_initializer(uv).run()\n",
    "    \n",
    "def reset_sess():\n",
    "    global sess\n",
    "    tf.reset_default_graph()\n",
    "    sess.close()\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded vocab data.\n",
      "Embedding <class 'numpy.ndarray'> (1004, 304) float64\n",
      "Word to index <class 'dict'> 1004\n",
      "Index to word <class 'list'> 1004\n",
      "\n",
      "Loaded train data.\n",
      "Captions <class 'numpy.ndarray'> (400135, 17) int32\n",
      "Image indices <class 'numpy.ndarray'> (400135,) int32\n",
      "Image features <class 'numpy.ndarray'> (82783, 4096) float32\n",
      "Image urls <class 'numpy.ndarray'> (82783,) <U63\n",
      "\n",
      "Loaded val data.\n",
      "Captions <class 'numpy.ndarray'> (195954, 17) int32\n",
      "Image indices <class 'numpy.ndarray'> (195954,) int32\n",
      "Image features <class 'numpy.ndarray'> (40504, 4096) float32\n",
      "Image urls <class 'numpy.ndarray'> (40504,) <U63\n"
     ]
    }
   ],
   "source": [
    "vocab_data, train_data, val_data = load_coco_data_struct()\n",
    "mledata = COCOData()\n",
    "pgdata = PGData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain\n",
    "Only run this section to pretrain the network again. This section will save the model which can then be loaded to immediately start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_iterations = 2\n",
    "mle_iterations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: -2.7806818252429366e-05\n"
     ]
    }
   ],
   "source": [
    "disc = DiscriminatorWrapper(train_data, val_data, vocab_data)\n",
    "initialize_sess()\n",
    "\n",
    "train_loss, val_loss = disc.pre_train(sess, iter_num=disc_iterations, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, cross-entropy: 110.80088806152344, accuracy: 0.0017376195173710585\n"
     ]
    }
   ],
   "source": [
    "lstm = MaxLikelihoodLSTM(tf.constant(mledata.word_embedding, dtype=tf.float32), learning_rate=5e-3, batch_size=100)\n",
    "lstm.build_model()\n",
    "initialize_sess()\n",
    "\n",
    "cross_entropy, accuracy = lstm.train(sess, mledata, max_iterations=mle_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the model into a models/ folder which is excluded from git using the .gitignore\n",
    "lstm.save_model(sess, \"pretrained-mle%d-disc%d\" % (mle_iterations, disc_iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_sess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "Load an existing model that contains both a discrminator and generator (policy gradient) network. If the model has contained a policy gradient LSTM before, then set is_PG to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/pretrained-mle3-disc2\n"
     ]
    }
   ],
   "source": [
    "dir_name=\"models\"\n",
    "model_name = \"pretrained-mle%d-disc%d\" % (mle_iterations, disc_iterations)\n",
    "is_PG = False\n",
    "\n",
    "# Load discriminator\n",
    "disc = DiscriminatorWrapper(train_data, val_data, vocab_data, load_session=sess,\n",
    "                            saved_model_name=model_name, model_base_dir=dir_name)\n",
    "\n",
    "# Load generator\n",
    "lstm = PolicyGradientLSTM(tf.constant(pgdata.word_embedding, dtype=tf.float32), learning_rate=5e-4, batch_size=100,\n",
    "                          reward_func=disc.assign_reward)\n",
    "lstm.load_model(sess, dir_name + \"/\" + model_name, is_PG=is_PG, restore_session=False)\n",
    "\n",
    "initialize_sess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Alternate between running the two cells below or enclose their contents in a loop. The former is probably wiser since sometimes either side will require fewer or more iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toilets black children men man a on man and <UNK> on on hanging building in and\n",
      "0.153965\n",
      "------------\n",
      "a chicken white the to the in a with holding the a that the <UNK> <UNK>\n",
      "0.154456\n",
      "------------\n",
      "man <UNK> next a <UNK> <UNK> a of the <END>\n",
      "0.115347\n",
      "------------\n",
      "white many train is there and game <UNK> in a <UNK> the the down city\n",
      "0.146845\n",
      "------------\n",
      "lush a <UNK> people and small a to to train the a small white\n",
      "0.162294\n",
      "------------\n",
      "beautiful <UNK> <UNK> giraffe in some to on <UNK> of in with group <UNK> of dog\n",
      "0.175958\n",
      "------------\n",
      "many one board an <UNK> <UNK> <UNK> in game <UNK> to parked with and and of\n",
      "0.187937\n",
      "------------\n",
      "many trucks <UNK> of small <UNK> the on in <UNK> with a and <UNK>\n",
      "0.188531\n",
      "------------\n",
      "standing <UNK> <UNK> <UNK> is <UNK> <UNK> city <UNK> <UNK> are baseball trees sky down game\n",
      "0.256971\n",
      "------------\n",
      "market <UNK> <UNK> <UNK> <UNK> signs <UNK> chicken <UNK> young adult <UNK> game <UNK> zebra\n",
      "0.263541\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "pg_iterations = 10\n",
    "captions = []\n",
    "probs = []\n",
    "indexes = []\n",
    "rewards = []\n",
    "\n",
    "for i in range(pg_iterations):\n",
    "    caption, prob, index, reward = lstm.train(sess, pgdata)\n",
    "    pgdata.shuffle()\n",
    "    print(np.mean(np.array(reward)[:, -1]))\n",
    "    print(\"------------\")\n",
    "    if i > 0.75 * pg_iterations:\n",
    "        captions.extend(caption)\n",
    "        probs.extend(prob)\n",
    "        indexes.extend(index)\n",
    "        rewards.extend(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 0.0011422252282500267\n"
     ]
    }
   ],
   "source": [
    "disc_iterations = 5\n",
    "\n",
    "online_all_loss, online_val_loss = disc.online_train(sess, iter_num=disc_iterations, img_idxs=np.array(indexes),\n",
    "                                                     caption_sentences=captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.save_model(sess, \"full-discriminator-generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

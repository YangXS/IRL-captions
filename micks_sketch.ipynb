{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from image_utils import image_from_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_image(batch_size):\n",
    "    captions, features, urls = sample_coco_minibatch(data, batch_size=batch_size)\n",
    "    for i, (caption, url) in enumerate(zip(captions, urls)):\n",
    "        plt.imshow(image_from_url(url))\n",
    "        plt.axis('off')\n",
    "        caption_str = decode_captions(caption, data['idx_to_word'])\n",
    "        plt.title(caption_str)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = load_coco_data(pca_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['val_features'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_image_idxs <class 'numpy.ndarray'> (400135,) int32\n",
      "val_captions <class 'numpy.ndarray'> (195954, 17) int32\n",
      "idx_to_word <class 'list'> 1004\n",
      "val_image_idxs <class 'numpy.ndarray'> (195954,) int32\n",
      "val_features <class 'numpy.ndarray'> (40504, 512) float32\n",
      "train_captions <class 'numpy.ndarray'> (400135, 17) int32\n",
      "word_to_idx <class 'dict'> 1004\n",
      "train_urls <class 'numpy.ndarray'> (82783,) <U63\n",
      "val_urls <class 'numpy.ndarray'> (40504,) <U63\n",
      "train_features <class 'numpy.ndarray'> (82783, 512) float32\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    if type(v) == np.ndarray:\n",
    "        print(k, type(v), v.shape, v.dtype)\n",
    "    else:\n",
    "        print(k, type(v), len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAEICAYAAADRFcoMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEWIAgGgRYgCAaBFiAIBoEWIAgGj9Lzv3JKgaGJOZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117e54550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sparse_to_one_hot(sparse_input, max_dim):\n",
    "    one_hot = np.zeros((sparse_input.shape[0], max_dim))\n",
    "    for idx, input_index in enumerate(sparse_input):\n",
    "        one_hot[idx, input_index] = 1\n",
    "    return one_hot\n",
    "\n",
    "def captions_to_one_hot(captions, vocab_dim):\n",
    "    return [sparse_to_one_hot(sentence, vocab_dim) for sentence in captions]\n",
    "\n",
    "def captions_to_target(captions, null_token_represenation):\n",
    "    \n",
    "    def trim_left_and_pad_right(caption):\n",
    "        \"\"\"\n",
    "        Convert training data:\n",
    "        '<START> a variety of fruits and vegetables sitting on a kitchen counter <END>'\n",
    "        to target:\n",
    "        'a variety of fruits and vegetables sitting on a kitchen counter <END> <NULL>'\n",
    "        \"\"\"\n",
    "        return np.append(caption[1::], null_token_represenation)\n",
    "    \n",
    "    return [trim_left_and_pad_right(c) for c in captions]\n",
    "\n",
    "def verify_caption_train_target_offset(train_caption, target_caption):\n",
    "    for i in range(len(target_caption) - 1):\n",
    "        assert train_caption[i + 1] == target_caption[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import layer_utils \n",
    "\n",
    "## word preprocess\n",
    "vocab_dim = len(data['word_to_idx'])\n",
    "image_feature_dim = data['val_features'].shape[1]\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "END_TOKEN = '<END>'\n",
    "NULL_TOKEN = '<NULL>'\n",
    "NULL_ID = data['word_to_idx'][NULL_TOKEN]\n",
    "\n",
    "## model params\n",
    "word_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "learning_rate = 5e-4\n",
    "\n",
    "def get_train_target_caption(train_captions_as_word_ids, to_one_hot = True):\n",
    "    \"\"\"\n",
    "        convert captions from word ids to representations [N, T, V], batch size, time step, and vocab size\n",
    "    \"\"\"\n",
    "\n",
    "    target_captions_as_word_ids = captions_to_target(train_captions_as_word_ids, data['word_to_idx'][NULL_TOKEN])\n",
    "    verify_caption_train_target_offset(train_captions_as_word_ids[0], target_captions_as_word_ids[0])\n",
    "\n",
    "    if (to_one_hot == False):\n",
    "        return train_captions_as_word_ids, target_captions_as_word_ids\n",
    "    else:\n",
    "        train_captions = captions_to_one_hot(train_captions_as_word_ids, vocab_dim)\n",
    "        return train_captions, target_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "manual_one_hot = False\n",
    "\n",
    "if manual_one_hot:\n",
    "    sy_caption_input = tf.placeholder(shape=[None, None, vocab_dim], name=\"caption_input\", dtype=tf.float32)\n",
    "    word_embedding = layer_utils.build_mlp(sy_caption_input, word_embedding_dim, 'word_embedding', activation=tf.nn.relu,  n_layers=1)\n",
    "else:\n",
    "    sy_caption_input = tf.placeholder(shape=[None, None], name=\"caption_input\", dtype=tf.int32)\n",
    "    embedding = tf.get_variable(\"embedding\", [vocab_dim, word_embedding_dim], dtype=tf.float32)\n",
    "    word_embedding = tf.nn.embedding_lookup(embedding, sy_caption_input)\n",
    "\n",
    "sy_caption_target = tf.placeholder(shape=[None, None], name=\"caption_target\", dtype=tf.int64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sy_image_feat_input = tf.placeholder(shape=[None, image_feature_dim], name=\"image_feat_input\", dtype=tf.float32)\n",
    "image_projection = layer_utils.affine_transform(sy_image_feat_input, image_feature_dim, 'image_proj')\n",
    "initial_cell_state = image_projection * 0\n",
    "initial_lstm_state = tf.nn.rnn_cell.LSTMStateTuple(initial_cell_state, image_projection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Input tensors --\n",
      "word embedding shape:  Tensor(\"embedding_lookup:0\", shape=(?, ?, 256), dtype=float32)\n",
      "hidden lstm:  Tensor(\"hidden_to_word/dense/BiasAdd:0\", shape=(?, ?, 1004), dtype=float32)\n",
      "\n",
      "-- Loss tensors --\n",
      "Target one hot:  Tensor(\"one_hot:0\", shape=(?, ?, 1004), dtype=int64)\n",
      "Mask not null:  Tensor(\"Cast:0\", shape=(?, ?), dtype=float32)\n",
      "Raw cross entropy:  Tensor(\"Reshape_2:0\", shape=(?, ?), dtype=float32)\n",
      "Masked cross entropy:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Cross entropy:  Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "\n",
      "-- Prediction tensors --\n",
      "target given:  Tensor(\"caption_target:0\", shape=(?, ?), dtype=int64)\n",
      "correct_pred prediction shape: Tensor(\"truediv:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_dim)\n",
    "outputs, final = tf.nn.dynamic_rnn(cell, word_embedding, time_major=False, dtype=tf.float32, initial_state=initial_lstm_state)\n",
    "hidden_to_word = layer_utils.affine_transform(outputs, vocab_dim, 'hidden_to_word')\n",
    "\n",
    "\n",
    "# Produce not-null mask. Padded words are null and has 0 mask\n",
    "mask_not_null = tf.cast(tf.not_equal(sy_caption_target, NULL_ID), dtype=tf.float32)\n",
    "# Get total non-null words to be predicted\n",
    "total_predictions = tf.cast(tf.reduce_sum(mask_not_null), tf.float32)\n",
    "\n",
    "# Process entropy from logits and one-hot target\n",
    "target_one_hot = tf.one_hot(sy_caption_target, vocab_dim, dtype=tf.int64)\n",
    "raw_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=target_one_hot, logits=hidden_to_word)\n",
    "masked_cross_entropy = raw_cross_entropy * mask_not_null\n",
    "cross_entropy = tf.reduce_mean(tf.reduce_sum(masked_cross_entropy, axis=1))\n",
    "update_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# Prediction accuracy\n",
    "prediction = tf.argmax(hidden_to_word, axis = 2)\n",
    "correct_pred = tf.equal(prediction, sy_caption_target)\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_pred, tf.float32))/total_predictions\n",
    "\n",
    "print(\"-- Input tensors --\")\n",
    "print(\"word embedding shape: \", word_embedding)\n",
    "print(\"hidden lstm: \", hidden_to_word)\n",
    "\n",
    "print(\"\\n-- Loss tensors --\")\n",
    "print(\"Target one hot: \", target_one_hot)\n",
    "print(\"Mask not null: \", mask_not_null)\n",
    "print(\"Raw cross entropy: \", raw_cross_entropy)\n",
    "print(\"Masked cross entropy: \", cross_entropy)\n",
    "print(\"Cross entropy: \", cross_entropy)\n",
    "\n",
    "print(\"\\n-- Prediction tensors --\")\n",
    "print(\"target given: \", sy_caption_target)\n",
    "print(\"correct_pred prediction shape:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_caption(session, initial_word, image_feature, limit_length):\n",
    "    \n",
    "    generated_word_idx = []\n",
    "    for _ in range(limit_length):\n",
    "        caption_input = [[initial_word]]\n",
    "        pred = session.run(prediction,feed_dict =\n",
    "                           {sy_caption_input: caption_input,\n",
    "                           sy_image_feat_input: features\n",
    "                           })[0][0]\n",
    "        \n",
    "        if type(initial_word) is list:\n",
    "            next_word_input = np.zeros(len(initial_word))\n",
    "            next_word_input[pred] = 1\n",
    "            initial_word = next_word_input\n",
    "        else:\n",
    "            initial_word = pred\n",
    "\n",
    "        generated_word_idx.append(pred)\n",
    "    print (decode_captions(np.array(generated_word_idx), data['idx_to_word']))\n",
    "    return generated_word_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, cross-entropy: 76.98063659667969, accuracy: 0.0008976660901680589\n",
      "iter 1, cross-entropy: 77.67218780517578, accuracy: 0.00711111119017005\n",
      "iter 2, cross-entropy: 77.29979705810547, accuracy: 0.01869991049170494\n",
      "iter 3, cross-entropy: 77.86027526855469, accuracy: 0.03883495181798935\n",
      "iter 4, cross-entropy: 77.66619873046875, accuracy: 0.07760141044855118\n",
      "iter 5, cross-entropy: 76.12541198730469, accuracy: 0.11210761964321136\n",
      "iter 6, cross-entropy: 73.36913299560547, accuracy: 0.13531047105789185\n",
      "iter 7, cross-entropy: 76.0527572631836, accuracy: 0.1666666716337204\n",
      "iter 8, cross-entropy: 75.74513244628906, accuracy: 0.16160714626312256\n",
      "iter 9, cross-entropy: 75.77684783935547, accuracy: 0.15794143080711365\n",
      "iter 10, cross-entropy: 74.22819519042969, accuracy: 0.1723826676607132\n",
      "iter 11, cross-entropy: 72.6464614868164, accuracy: 0.18693284690380096\n",
      "iter 12, cross-entropy: 72.63824462890625, accuracy: 0.1964125633239746\n",
      "iter 13, cross-entropy: 69.96357727050781, accuracy: 0.21167883276939392\n",
      "iter 14, cross-entropy: 72.07056427001953, accuracy: 0.1931818127632141\n",
      "iter 15, cross-entropy: 68.56922912597656, accuracy: 0.19175627827644348\n",
      "iter 16, cross-entropy: 67.37948608398438, accuracy: 0.18197879195213318\n",
      "iter 17, cross-entropy: 63.133670806884766, accuracy: 0.17375566065311432\n",
      "iter 18, cross-entropy: 61.86537551879883, accuracy: 0.1505861133337021\n",
      "iter 19, cross-entropy: 59.575714111328125, accuracy: 0.16335740685462952\n",
      "iter 20, cross-entropy: 58.636993408203125, accuracy: 0.19780220091342926\n",
      "iter 21, cross-entropy: 60.43318176269531, accuracy: 0.1854838728904724\n",
      "iter 22, cross-entropy: 58.97618103027344, accuracy: 0.17379678785800934\n",
      "iter 23, cross-entropy: 58.86882019042969, accuracy: 0.16490299999713898\n",
      "iter 24, cross-entropy: 57.262176513671875, accuracy: 0.17198581993579865\n",
      "iter 25, cross-entropy: 58.64336013793945, accuracy: 0.18000000715255737\n",
      "iter 26, cross-entropy: 56.693389892578125, accuracy: 0.11828935146331787\n",
      "iter 27, cross-entropy: 55.35775375366211, accuracy: 0.1365678310394287\n",
      "iter 28, cross-entropy: 56.87299346923828, accuracy: 0.11634103208780289\n",
      "iter 29, cross-entropy: 55.4283561706543, accuracy: 0.18942731618881226\n",
      "iter 30, cross-entropy: 57.49492263793945, accuracy: 0.1923743486404419\n",
      "iter 31, cross-entropy: 53.92555236816406, accuracy: 0.19563239812850952\n",
      "iter 32, cross-entropy: 53.103946685791016, accuracy: 0.1913919448852539\n",
      "iter 33, cross-entropy: 54.826663970947266, accuracy: 0.18558558821678162\n",
      "iter 34, cross-entropy: 52.253639221191406, accuracy: 0.18555758893489838\n",
      "iter 35, cross-entropy: 54.1409912109375, accuracy: 0.1897018998861313\n",
      "iter 36, cross-entropy: 53.83320236206055, accuracy: 0.1854838728904724\n",
      "iter 37, cross-entropy: 53.85525894165039, accuracy: 0.19124217331409454\n",
      "iter 38, cross-entropy: 54.90757369995117, accuracy: 0.19337978959083557\n",
      "iter 39, cross-entropy: 52.75907897949219, accuracy: 0.2071748822927475\n",
      "iter 40, cross-entropy: 54.76383972167969, accuracy: 0.1927083283662796\n",
      "iter 41, cross-entropy: 53.74879837036133, accuracy: 0.203027606010437\n",
      "iter 42, cross-entropy: 52.828731536865234, accuracy: 0.1989198923110962\n",
      "iter 43, cross-entropy: 51.453067779541016, accuracy: 0.20742753148078918\n",
      "iter 44, cross-entropy: 50.585479736328125, accuracy: 0.21448467671871185\n",
      "iter 45, cross-entropy: 52.537879943847656, accuracy: 0.19838419556617737\n",
      "iter 46, cross-entropy: 50.41078186035156, accuracy: 0.20260223746299744\n",
      "iter 47, cross-entropy: 51.35362243652344, accuracy: 0.20773380994796753\n",
      "iter 48, cross-entropy: 50.916542053222656, accuracy: 0.2010820508003235\n",
      "iter 49, cross-entropy: 51.238304138183594, accuracy: 0.19328494369983673\n",
      "iter 50, cross-entropy: 52.81499099731445, accuracy: 0.20974761247634888\n",
      "iter 51, cross-entropy: 52.02528381347656, accuracy: 0.21114106476306915\n",
      "iter 52, cross-entropy: 53.71687316894531, accuracy: 0.20650263130664825\n",
      "iter 53, cross-entropy: 50.40562438964844, accuracy: 0.21834862232208252\n",
      "iter 54, cross-entropy: 51.7193603515625, accuracy: 0.19964028894901276\n",
      "iter 55, cross-entropy: 52.3759765625, accuracy: 0.1817367970943451\n",
      "iter 56, cross-entropy: 50.7739372253418, accuracy: 0.21146953105926514\n",
      "iter 57, cross-entropy: 49.797691345214844, accuracy: 0.22302810847759247\n",
      "iter 58, cross-entropy: 51.60030746459961, accuracy: 0.21685689687728882\n",
      "iter 59, cross-entropy: 50.920597076416016, accuracy: 0.21344232559204102\n",
      "iter 60, cross-entropy: 50.936561584472656, accuracy: 0.2139037400484085\n",
      "iter 61, cross-entropy: 51.43272399902344, accuracy: 0.22192513942718506\n",
      "iter 62, cross-entropy: 50.53329086303711, accuracy: 0.21146953105926514\n",
      "iter 63, cross-entropy: 51.273956298828125, accuracy: 0.2007233202457428\n",
      "iter 64, cross-entropy: 50.872745513916016, accuracy: 0.21992819011211395\n",
      "iter 65, cross-entropy: 51.3792839050293, accuracy: 0.21113073825836182\n",
      "iter 66, cross-entropy: 52.49089431762695, accuracy: 0.2039930522441864\n",
      "iter 67, cross-entropy: 51.1085205078125, accuracy: 0.21940559148788452\n",
      "iter 68, cross-entropy: 50.5768928527832, accuracy: 0.20940549671649933\n",
      "iter 69, cross-entropy: 51.10822677612305, accuracy: 0.21719858050346375\n",
      "iter 70, cross-entropy: 48.602508544921875, accuracy: 0.22723174095153809\n",
      "iter 71, cross-entropy: 48.73697280883789, accuracy: 0.22536496818065643\n",
      "iter 72, cross-entropy: 49.6154670715332, accuracy: 0.20844563841819763\n",
      "iter 73, cross-entropy: 50.905948638916016, accuracy: 0.23728813230991364\n",
      "iter 74, cross-entropy: 50.734920501708984, accuracy: 0.22994652390480042\n",
      "iter 75, cross-entropy: 50.192840576171875, accuracy: 0.2321428507566452\n",
      "iter 76, cross-entropy: 50.10524368286133, accuracy: 0.22163119912147522\n",
      "iter 77, cross-entropy: 47.893310546875, accuracy: 0.2398897111415863\n",
      "iter 78, cross-entropy: 47.946075439453125, accuracy: 0.2362278252840042\n",
      "iter 79, cross-entropy: 46.9809455871582, accuracy: 0.24217310547828674\n",
      "iter 80, cross-entropy: 49.13629913330078, accuracy: 0.21687839925289154\n",
      "iter 81, cross-entropy: 48.62590026855469, accuracy: 0.23518851399421692\n",
      "iter 82, cross-entropy: 50.86796569824219, accuracy: 0.21052631735801697\n",
      "iter 83, cross-entropy: 48.49850082397461, accuracy: 0.23139013350009918\n",
      "iter 84, cross-entropy: 47.2685546875, accuracy: 0.24495412409305573\n",
      "iter 85, cross-entropy: 48.664161682128906, accuracy: 0.22171945869922638\n",
      "iter 86, cross-entropy: 49.595909118652344, accuracy: 0.24394619464874268\n",
      "iter 87, cross-entropy: 49.604759216308594, accuracy: 0.24375000596046448\n",
      "iter 88, cross-entropy: 47.868186950683594, accuracy: 0.24264049530029297\n",
      "iter 89, cross-entropy: 46.91732406616211, accuracy: 0.24339106678962708\n",
      "iter 90, cross-entropy: 48.066192626953125, accuracy: 0.23887374997138977\n",
      "iter 91, cross-entropy: 47.879451751708984, accuracy: 0.2524619400501251\n",
      "iter 92, cross-entropy: 48.190895080566406, accuracy: 0.24550360441207886\n",
      "iter 93, cross-entropy: 47.55951690673828, accuracy: 0.26296958327293396\n",
      "iter 94, cross-entropy: 48.021461486816406, accuracy: 0.23300090432167053\n",
      "iter 95, cross-entropy: 47.61320495605469, accuracy: 0.2633928656578064\n",
      "iter 96, cross-entropy: 48.594139099121094, accuracy: 0.2535587251186371\n",
      "iter 97, cross-entropy: 46.54560470581055, accuracy: 0.2390909045934677\n",
      "iter 98, cross-entropy: 46.656455993652344, accuracy: 0.2511052191257477\n",
      "iter 99, cross-entropy: 46.8906364440918, accuracy: 0.23482142388820648\n"
     ]
    }
   ],
   "source": [
    "iter_num = 100\n",
    "embeddings = []\n",
    "for i in range(iter_num):\n",
    "    mini_batch, features, url = sample_coco_minibatch(data,  batch_size=100, split='train')\n",
    "    train_captions, target_captions = get_train_target_caption(mini_batch, to_one_hot=False)\n",
    "#     o, c, m, a, p, cp = sess.run([update_op, reduced_cross_entropy, masked_cross_entropy, accuracy, prediction, correct_pred], {sy_caption_input: train_captions, sy_caption_target: target_captions})\n",
    "    _, c, a = sess.run([update_op, cross_entropy, accuracy], feed_dict=\n",
    "                       {sy_image_feat_input: features,\n",
    "                        sy_caption_input: train_captions, \n",
    "                        sy_caption_target: target_captions\n",
    "                       })\n",
    "    print(\"iter {}, cross-entropy: {}, accuracy: {}\".format(i, c, a))\n",
    "#     if (i%20 == 0):\n",
    "#         sample_caption(sess, train_captions[0][1], 17)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deeprl]",
   "language": "python",
   "name": "conda-env-deeprl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
